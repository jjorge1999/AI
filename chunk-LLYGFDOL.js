import{a as p}from"./chunk-F3KV3B6D.js";import{K as l,P as f,U as A,i as s,j as r,o as m,qc as d,x as a}from"./chunk-OKMRB5PS.js";import{g}from"./chunk-7QOE2ANW.js";var L=(()=>{class c{constructor(e){this.settingsService=e,this.sentimentPipeline=null,this.generationPipeline=null,this.isLoading=!1,this.localModelsSupported=!0,this.HF_API_URL="https://router.huggingface.co/v1/chat/completions",this.useGemmaApi=!0,this.AI_MODELS=["google/gemma-2-2b-it","meta-llama/Llama-3.2-3B-Instruct","mistralai/Mistral-7B-Instruct-v0.3","Qwen/Qwen2.5-1.5B-Instruct","Qwen/Qwen2.5-VL-7B-Instruct"],this.VISION_MODEL="Qwen/Qwen2.5-VL-7B-Instruct",this.currentModelIndex=0}getHfToken(){return this.settingsService.getHuggingFaceToken()||d.huggingFaceToken||null}setHuggingFaceToken(e){localStorage.setItem("hf_token",e),console.log("AI Service: Hugging Face token set")}isGemmaApiAvailable(){let e=this.getHfToken();return!!e&&e.startsWith("hf_")}setUseGemmaApi(e=!0){this.useGemmaApi=e,console.log(`AI Service: Using ${e?"Gemma API":"Local Models"}`)}init(){return this.sentimentPipeline&&this.generationPipeline||this.isLoading?r(void 0):this.localModelsSupported?(this.isLoading=!0,s(import("./chunk-C33ARDKD.js")).pipe(l(e=>g(this,null,function*(){let{pipeline:t}=e;this.sentimentPipeline||(this.sentimentPipeline=yield t("sentiment-analysis","Xenova/distilbert-base-uncased-finetuned-sst-2-english")),this.generationPipeline||(this.generationPipeline=yield t("text2text-generation","Xenova/LaMini-Flan-T5-77M"))})),m(()=>{console.log("AI Service: Local models loaded successfully"),this.isLoading=!1}),a(e=>(console.error("AI Service: Failed to load local AI models",e),console.log("AI Service: Falling back to Gemma API only"),this.localModelsSupported=!1,this.isLoading=!1,r(void 0))))):(console.log("AI Service: Local models not supported on this browser, using Gemma API only"),r(void 0))}analyzeSentiment(e){return this.init().pipe(l(()=>this.sentimentPipeline?s(this.sentimentPipeline(e)):r(null)),m(t=>Array.isArray(t)&&t.length>0?t[0]:null),a(t=>(console.error("AI Service: Sentiment analysis failed",t),r(null))))}generateText(e){return this.useGemmaApi&&this.getHfToken()?this.generateWithGemma(e).pipe(l(t=>t?r(t):(console.log("AI Service: Gemma API failed, falling back to local model"),this.generateWithLocalModel(e)))):this.generateWithLocalModel(e)}generateWithGemma(e){let t=this.getHfToken();return t?this.tryModelWithFallback(e,t,0):(console.warn("AI Service: No Hugging Face token available for Gemma API"),r(null))}tryModelWithFallback(e,t,o){if(o>=this.AI_MODELS.length)return console.warn("AI Service: All models exhausted, falling back to local"),r(null);let n=this.AI_MODELS[o];return console.log(`AI Service: Trying model ${n}`),s(fetch(this.HF_API_URL,{method:"POST",headers:{Authorization:`Bearer ${t}`,"Content-Type":"application/json"},body:JSON.stringify({model:n,messages:[{role:"user",content:e}],max_tokens:150,temperature:.7})})).pipe(l(i=>g(this,null,function*(){if(!i.ok){let u=yield i.json().catch(()=>({}));return console.error(`AI Service: Model ${n} error`,i.status,u),i.status===402||i.status===429?(console.log(`AI Service: ${n} rate limited, trying next model...`),{tryNext:!0}):i.status===503?(console.log(`AI Service: ${n} is loading, trying next model...`),{tryNext:!0}):null}return i.json()})),l(i=>{if(i&&i.tryNext)return this.tryModelWithFallback(e,t,o+1);if(!i)return r(null);if(i.choices&&i.choices.length>0){let h=i.choices[0].message?.content?.trim()||null;return h&&(console.log(`AI Service: Successfully used model ${n}`),this.currentModelIndex=o),r(h)}return r(null)}),a(i=>(console.error(`AI Service: ${n} failed`,i),o+1<this.AI_MODELS.length?this.tryModelWithFallback(e,t,o+1):r(null))))}generateWithLocalModel(e){return this.init().pipe(l(()=>this.generationPipeline?s(this.generationPipeline(e,{max_new_tokens:60,temperature:.7,repetition_penalty:1.2})):r(null)),m(t=>Array.isArray(t)&&t.length>0?t[0].generated_text:null),a(t=>(console.error("AI Service: Local generation failed",t),r(null))))}chatWithGemma(e){let t=this.getHfToken();if(!t)return console.warn("AI Service: No Hugging Face token for Gemma chat"),r(null);let o=e.map(n=>({role:n.role==="model"?"assistant":n.role,content:n.content}));return this.tryChatWithFallback(o,t,0)}tryChatWithFallback(e,t,o){if(o>=this.AI_MODELS.length)return console.warn("AI Service: All models exhausted for chat"),r(null);let n=this.AI_MODELS[o];return console.log(`AI Service: Trying chat model ${n}`),s(fetch(this.HF_API_URL,{method:"POST",headers:{Authorization:`Bearer ${t}`,"Content-Type":"application/json"},body:JSON.stringify({model:n,messages:e,max_tokens:200,temperature:.7})})).pipe(l(i=>g(this,null,function*(){if(!i.ok){let u=yield i.json().catch(()=>({}));return console.error(`AI Service: Chat model ${n} error`,i.status,u),i.status===402||i.status===429||i.status===503?(console.log(`AI Service: ${n} unavailable, trying next...`),{tryNext:!0}):null}return i.json()})),l(i=>{if(i&&i.tryNext)return this.tryChatWithFallback(e,t,o+1);if(!i)return r(null);if(i.choices&&i.choices.length>0){let h=i.choices[0].message?.content?.trim()||null;return h&&console.log(`AI Service: Chat successfully used model ${n}`),r(h)}return r(null)}),a(i=>(console.error(`AI Service: Chat ${n} failed`,i),o+1<this.AI_MODELS.length?this.tryChatWithFallback(e,t,o+1):r(null))))}analyzeImage(e,t){let o=this.getHfToken();return o?s(fetch(this.HF_API_URL,{method:"POST",headers:{Authorization:`Bearer ${o}`,"Content-Type":"application/json"},body:JSON.stringify({model:this.VISION_MODEL,messages:[{role:"user",content:[{type:"text",text:t},{type:"image_url",image_url:{url:e}}]}],max_tokens:100})})).pipe(l(n=>g(this,null,function*(){return n.ok?n.json():null})),m(n=>n?.choices?.length>0&&n.choices[0].message?.content||null),a(n=>(console.error("AI Service: Image analysis failed",n),r(null)))):r(null)}static{this.\u0275fac=function(t){return new(t||c)(A(p))}}static{this.\u0275prov=f({token:c,factory:c.\u0275fac,providedIn:"root"})}}return c})();export{L as a};
